{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b5e44d0",
   "metadata": {},
   "source": [
    "# Callable Traits\n",
    "\n",
    "Callable traits evaluate LLM responses using **custom Python functions**. They give you full programmatic control over evaluation logic -- from simple word count checks to complex domain-specific scoring -- without requiring an LLM call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "136451ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T01:45:39.021591Z",
     "iopub.status.busy": "2026-02-06T01:45:39.021374Z",
     "iopub.status.idle": "2026-02-06T01:45:39.026818Z",
     "shell.execute_reply": "2026-02-06T01:45:39.026326Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Mock cell: ensures examples execute without live API keys.\n",
    "# This cell is hidden in rendered documentation.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Deserializing callable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fed5cff",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A `CallableTrait` wraps a Python function that takes the response text as input and returns either a boolean (pass/fail) or an integer score. The function is serialized using [cloudpickle](https://github.com/cloudpipe/cloudpickle) so it can be stored in checkpoint files.\n",
    "\n",
    "| Field | Type | Default | Description |\n",
    "|-------|------|---------|-------------|\n",
    "| `name` | `str` | *(required)* | Human-readable identifier |\n",
    "| `description` | `str \\| None` | `None` | What this trait evaluates |\n",
    "| `kind` | `str` | *(required)* | `\"boolean\"` for pass/fail, `\"score\"` for numeric |\n",
    "| `callable_code` | `bytes` | *(required)* | Serialized function (cloudpickle) |\n",
    "| `min_score` | `int \\| None` | `None` | Minimum score (required if `kind=\"score\"`) |\n",
    "| `max_score` | `int \\| None` | `None` | Maximum score (required if `kind=\"score\"`) |\n",
    "| `invert_result` | `bool` | `False` | Invert the boolean result (only for `kind=\"boolean\"`) |\n",
    "| `higher_is_better` | `bool` | *(required)* | Whether higher return values indicate better performance |\n",
    "\n",
    "**Key characteristics:**\n",
    "\n",
    "- Returns **boolean** or **integer** depending on `kind`\n",
    "- No LLM call required -- evaluated locally by running your function\n",
    "- Function must accept exactly **one `str` parameter** (the response text)\n",
    "- Function is serialized via cloudpickle -- lambda functions and module-level functions work best\n",
    "- Use the `from_callable()` class method to create traits (handles serialization automatically)\n",
    "\n",
    "## Creating with `from_callable()`\n",
    "\n",
    "Always use `CallableTrait.from_callable()` rather than constructing directly -- it validates the function signature and handles serialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b7f3fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T01:45:39.029245Z",
     "iopub.status.busy": "2026-02-06T01:45:39.029069Z",
     "iopub.status.idle": "2026-02-06T01:45:39.380720Z",
     "shell.execute_reply": "2026-02-06T01:45:39.380476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from karenina.schemas import CallableTrait\n",
    "\n",
    "# Boolean callable: check minimum word count\n",
    "word_count_trait = CallableTrait.from_callable(\n",
    "    name=\"Minimum Word Count\",\n",
    "    description=\"Response must contain at least 50 words\",\n",
    "    func=lambda text: len(text.split()) >= 50,\n",
    "    kind=\"boolean\",\n",
    "    higher_is_better=True,  # Passing the check is good\n",
    ")\n",
    "\n",
    "# Evaluate against sample responses\n",
    "short_response = \"The answer is BCL2.\"\n",
    "long_response = \"The drug target is BCL2. \" * 20\n",
    "\n",
    "print(word_count_trait.evaluate(short_response))  # False (too short)\n",
    "print(word_count_trait.evaluate(long_response))    # True (long enough)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e422b92b",
   "metadata": {},
   "source": [
    "## Score-Based Callables\n",
    "\n",
    "Score callables return an integer within a defined range. You must specify `min_score` and `max_score`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181d6726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T01:45:39.381871Z",
     "iopub.status.busy": "2026-02-06T01:45:39.381788Z",
     "iopub.status.idle": "2026-02-06T01:45:39.384000Z",
     "shell.execute_reply": "2026-02-06T01:45:39.383829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 3\n"
     ]
    }
   ],
   "source": [
    "def count_sentences(text: str) -> int:\n",
    "    \"\"\"Count the number of sentences in the text.\"\"\"\n",
    "    import re\n",
    "    sentences = re.split(r'[.!?]+', text.strip())\n",
    "    return len([s for s in sentences if s.strip()])\n",
    "\n",
    "sentence_count_trait = CallableTrait.from_callable(\n",
    "    name=\"Sentence Count\",\n",
    "    description=\"Count the number of sentences in the response\",\n",
    "    func=count_sentences,\n",
    "    kind=\"score\",\n",
    "    min_score=0,\n",
    "    max_score=100,\n",
    "    higher_is_better=True,  # More sentences = more detailed\n",
    ")\n",
    "\n",
    "sample = \"BCL2 is a proto-oncogene. It regulates apoptosis. It is located on chromosome 18.\"\n",
    "print(f\"Score: {sentence_count_trait.evaluate(sample)}\")  # Score: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf598b3",
   "metadata": {},
   "source": [
    "## Inverted Boolean Callables\n",
    "\n",
    "For boolean traits, `invert_result=True` flips the function's return value. This is useful when your function detects something undesirable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fc5b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T01:45:39.384988Z",
     "iopub.status.busy": "2026-02-06T01:45:39.384931Z",
     "iopub.status.idle": "2026-02-06T01:45:39.386800Z",
     "shell.execute_reply": "2026-02-06T01:45:39.386628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Detect excessive repetition (bad), so invert the result\n",
    "repetition_trait = CallableTrait.from_callable(\n",
    "    name=\"No Excessive Repetition\",\n",
    "    description=\"Response should not repeat the same sentence excessively\",\n",
    "    func=lambda text: len(set(text.split(\". \"))) < len(text.split(\". \")) * 0.5,\n",
    "    kind=\"boolean\",\n",
    "    invert_result=True,  # True from func means repetition detected -> invert to False\n",
    "    higher_is_better=True,  # True (no repetition) is good\n",
    ")\n",
    "\n",
    "print(repetition_trait.evaluate(\"Unique sentence one. Unique sentence two. Unique sentence three.\"))  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100c8a8",
   "metadata": {},
   "source": [
    "## The `higher_is_better` Field\n",
    "\n",
    "The `higher_is_better` field controls how results are interpreted in aggregate analysis:\n",
    "\n",
    "| `higher_is_better` | Meaning | Example |\n",
    "|---------------------|---------|---------|\n",
    "| `True` | Higher values = better performance | Word count, detail score |\n",
    "| `False` | Lower values = better performance | Error count, complexity penalty |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6afdb1d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T01:45:39.387688Z",
     "iopub.status.busy": "2026-02-06T01:45:39.387631Z",
     "iopub.status.idle": "2026-02-06T01:45:39.389363Z",
     "shell.execute_reply": "2026-02-06T01:45:39.389164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 3\n"
     ]
    }
   ],
   "source": [
    "# Error count: lower is better\n",
    "error_count_trait = CallableTrait.from_callable(\n",
    "    name=\"Grammar Error Count\",\n",
    "    description=\"Count potential grammar errors (lower is better)\",\n",
    "    func=lambda text: text.count(\"  \"),  # Simple: count double spaces as errors\n",
    "    kind=\"score\",\n",
    "    min_score=0,\n",
    "    max_score=50,\n",
    "    higher_is_better=False,  # Fewer errors is better\n",
    ")\n",
    "\n",
    "print(f\"Errors: {error_count_trait.evaluate('Clean  text with  two double  spaces.')}\")  # Errors: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93dd46",
   "metadata": {},
   "source": [
    "## Deserializing and Inspecting\n",
    "\n",
    "You can retrieve the stored function using `deserialize_callable()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee13f74c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T01:45:39.390266Z",
     "iopub.status.busy": "2026-02-06T01:45:39.390216Z",
     "iopub.status.idle": "2026-02-06T01:45:39.391908Z",
     "shell.execute_reply": "2026-02-06T01:45:39.391743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function result: 11\n",
      "Trait evaluate:  11\n"
     ]
    }
   ],
   "source": [
    "# Create a trait\n",
    "length_trait = CallableTrait.from_callable(\n",
    "    name=\"Response Length\",\n",
    "    func=lambda text: len(text),\n",
    "    kind=\"score\",\n",
    "    min_score=0,\n",
    "    max_score=10000,\n",
    "    higher_is_better=True,\n",
    ")\n",
    "\n",
    "# Deserialize and call directly\n",
    "func = length_trait.deserialize_callable()\n",
    "print(f\"Function result: {func('Hello world')}\")  # Function result: 11\n",
    "print(f\"Trait evaluate:  {length_trait.evaluate('Hello world')}\")  # Trait evaluate:  11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d83444",
   "metadata": {},
   "source": [
    "!!! warning \"Security Warning\"\n",
    "    Deserializing callable code can execute arbitrary Python code. Only load `CallableTrait` instances from **trusted sources**. `CallableTrait` cannot be created via the web API for security reasons.\n",
    "\n",
    "## Serialization Best Practices\n",
    "\n",
    "The function is serialized with cloudpickle when you call `from_callable()`. Follow these guidelines:\n",
    "\n",
    "- **Use lambda functions** for simple logic -- they serialize cleanly\n",
    "- **Use module-level named functions** for complex logic -- they are more reliable than nested functions\n",
    "- **Avoid closures over large objects** -- the entire closure state is serialized\n",
    "- **Avoid unpicklable state** -- database connections, file handles, and thread locks cannot be serialized\n",
    "- **Keep dependencies minimal** -- the deserializing environment must have the same packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205dfaa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T01:45:39.392861Z",
     "iopub.status.busy": "2026-02-06T01:45:39.392797Z",
     "iopub.status.idle": "2026-02-06T01:45:39.394731Z",
     "shell.execute_reply": "2026-02-06T01:45:39.394541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Good: lambda\n",
    "trait_a = CallableTrait.from_callable(\n",
    "    name=\"Has Keywords\",\n",
    "    func=lambda text: any(kw in text.lower() for kw in [\"target\", \"mechanism\", \"pathway\"]),\n",
    "    kind=\"boolean\",\n",
    "    higher_is_better=True,\n",
    ")\n",
    "\n",
    "# Good: module-level function (defined above in this example)\n",
    "trait_b = CallableTrait.from_callable(\n",
    "    name=\"Sentence Count\",\n",
    "    func=count_sentences,\n",
    "    kind=\"score\",\n",
    "    min_score=0,\n",
    "    max_score=100,\n",
    "    higher_is_better=True,\n",
    ")\n",
    "\n",
    "print(trait_a.evaluate(\"The drug's mechanism of action involves BCL2.\"))  # True\n",
    "print(trait_a.evaluate(\"The answer is 42.\"))  # False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2518d",
   "metadata": {},
   "source": [
    "## Using Callable Traits in a Rubric\n",
    "\n",
    "Callable traits combine with other trait types in a `Rubric`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d61eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T01:45:39.395604Z",
     "iopub.status.busy": "2026-02-06T01:45:39.395557Z",
     "iopub.status.idle": "2026-02-06T01:45:39.397724Z",
     "shell.execute_reply": "2026-02-06T01:45:39.397540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rubric has 2 callable traits\n",
      "  - Minimum Length (kind=boolean)\n",
      "  - Technical Depth (kind=score)\n"
     ]
    }
   ],
   "source": [
    "from karenina.schemas import CallableTrait, Rubric\n",
    "\n",
    "rubric = Rubric(callable_traits=[\n",
    "    CallableTrait.from_callable(\n",
    "        name=\"Minimum Length\",\n",
    "        description=\"Response must be at least 100 characters\",\n",
    "        func=lambda text: len(text) >= 100,\n",
    "        kind=\"boolean\",\n",
    "        higher_is_better=True,\n",
    "    ),\n",
    "    CallableTrait.from_callable(\n",
    "        name=\"Technical Depth\",\n",
    "        description=\"Count technical terms as a quality proxy\",\n",
    "        func=lambda text: sum(1 for term in [\"gene\", \"protein\", \"pathway\", \"mechanism\", \"target\"]\n",
    "                              if term in text.lower()),\n",
    "        kind=\"score\",\n",
    "        min_score=0,\n",
    "        max_score=20,\n",
    "        higher_is_better=True,\n",
    "    ),\n",
    "])\n",
    "\n",
    "print(f\"Rubric has {len(rubric.callable_traits)} callable traits\")\n",
    "for trait in rubric.callable_traits:\n",
    "    print(f\"  - {trait.name} (kind={trait.kind})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c9eba",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- [LLM Traits](llm-traits.md) -- Boolean and score traits evaluated by an LLM judge\n",
    "- [Literal Traits](literal-traits.md) -- Ordered categorical classification via LLM\n",
    "- [Regex Traits](regex-traits.md) -- Deterministic pattern matching\n",
    "- [Metric Traits](metric-traits.md) -- Precision, recall, and F1 for extraction tasks\n",
    "- [Defining Rubrics](../../05-creating-benchmarks/defining-rubrics.md) -- Adding traits to benchmarks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
