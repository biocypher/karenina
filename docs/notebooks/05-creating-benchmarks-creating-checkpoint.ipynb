{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93fcc86b",
   "metadata": {},
   "source": [
    "# Creating a Checkpoint\n",
    "\n",
    "A **checkpoint** is a Karenina benchmark file in JSON-LD format. Creating one is the first step in building any benchmark. This page covers the `Benchmark` constructor, metadata fields, and inspecting your new benchmark.\n",
    "\n",
    "For background on what checkpoints are and why they use JSON-LD, see [Checkpoints](../04-core-concepts/checkpoints.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e44694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T00:31:41.256991Z",
     "iopub.status.busy": "2026-02-06T00:31:41.256867Z",
     "iopub.status.idle": "2026-02-06T00:31:41.259850Z",
     "shell.execute_reply": "2026-02-06T00:31:41.259460Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup cell (hidden in rendered docs).\n",
    "# No mocking needed — all examples create Benchmark objects locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379847a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating a Benchmark\n",
    "\n",
    "Use the `Benchmark` constructor or the `Benchmark.create()` class method (they are equivalent):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f3c1aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T00:31:41.261502Z",
     "iopub.status.busy": "2026-02-06T00:31:41.261384Z",
     "iopub.status.idle": "2026-02-06T00:31:41.582893Z",
     "shell.execute_reply": "2026-02-06T00:31:41.582654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: Genomics Knowledge Benchmark\n"
     ]
    }
   ],
   "source": [
    "from karenina import Benchmark\n",
    "\n",
    "# Using the constructor\n",
    "benchmark = Benchmark(name=\"Genomics Knowledge Benchmark\")\n",
    "\n",
    "# Or equivalently, using the class method\n",
    "benchmark = Benchmark.create(name=\"Genomics Knowledge Benchmark\")\n",
    "\n",
    "print(f\"Created: {benchmark.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee114102",
   "metadata": {},
   "source": [
    "## Constructor Parameters\n",
    "\n",
    "The constructor accepts four parameters:\n",
    "\n",
    "| Parameter | Type | Default | Description |\n",
    "|-----------|------|---------|-------------|\n",
    "| `name` | `str` | *(required)* | Name of the benchmark |\n",
    "| `description` | `str` | `\"\"` | Human-readable description of the benchmark's purpose |\n",
    "| `version` | `str` | `\"0.1.0\"` | Version string for tracking benchmark evolution |\n",
    "| `creator` | `str` | `\"Karenina Benchmarking System\"` | Creator name or organization |\n",
    "\n",
    "Here is a benchmark with all metadata fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbdf4f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T00:31:41.584015Z",
     "iopub.status.busy": "2026-02-06T00:31:41.583930Z",
     "iopub.status.idle": "2026-02-06T00:31:41.585739Z",
     "shell.execute_reply": "2026-02-06T00:31:41.585572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        Drug Target Identification\n",
      "Description: Evaluates LLM knowledge of drug mechanisms and molecular targets\n",
      "Version:     1.0.0\n",
      "Creator:     Pharmacology Research Lab\n"
     ]
    }
   ],
   "source": [
    "benchmark = Benchmark.create(\n",
    "    name=\"Drug Target Identification\",\n",
    "    description=\"Evaluates LLM knowledge of drug mechanisms and molecular targets\",\n",
    "    version=\"1.0.0\",\n",
    "    creator=\"Pharmacology Research Lab\",\n",
    ")\n",
    "\n",
    "print(f\"Name:        {benchmark.name}\")\n",
    "print(f\"Description: {benchmark.description}\")\n",
    "print(f\"Version:     {benchmark.version}\")\n",
    "print(f\"Creator:     {benchmark.creator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2e28c9",
   "metadata": {},
   "source": [
    "## Inspecting a Benchmark\n",
    "\n",
    "A freshly created benchmark starts empty. You can check its state using these properties and methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc1feac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T00:31:41.586686Z",
     "iopub.status.busy": "2026-02-06T00:31:41.586632Z",
     "iopub.status.idle": "2026-02-06T00:31:41.588067Z",
     "shell.execute_reply": "2026-02-06T00:31:41.587862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question count:  0\n",
      "Finished count:  0\n",
      "Is empty:        True\n",
      "Is complete:     False\n",
      "Progress:        0.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Question count:  {benchmark.question_count}\")\n",
    "print(f\"Finished count:  {benchmark.finished_count}\")\n",
    "print(f\"Is empty:        {benchmark.is_empty}\")\n",
    "print(f\"Is complete:     {benchmark.is_complete}\")\n",
    "print(f\"Progress:        {benchmark.get_progress()}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdea5df",
   "metadata": {},
   "source": [
    "### Timestamps\n",
    "\n",
    "Every benchmark tracks when it was created and last modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bdabca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T00:31:41.589066Z",
     "iopub.status.busy": "2026-02-06T00:31:41.589014Z",
     "iopub.status.idle": "2026-02-06T00:31:41.590508Z",
     "shell.execute_reply": "2026-02-06T00:31:41.590334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created at:  2026-02-06T00:31:41.584401\n",
      "Modified at: 2026-02-06T00:31:41.584401\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created at:  {benchmark.created_at}\")\n",
    "print(f\"Modified at: {benchmark.modified_at}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc55aa",
   "metadata": {},
   "source": [
    "### Mutable Metadata\n",
    "\n",
    "All metadata fields are writable after creation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0770b2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T00:31:41.591459Z",
     "iopub.status.busy": "2026-02-06T00:31:41.591394Z",
     "iopub.status.idle": "2026-02-06T00:31:41.592906Z",
     "shell.execute_reply": "2026-02-06T00:31:41.592745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New version:     1.1.0\n",
      "New description: Updated description with expanded scope\n"
     ]
    }
   ],
   "source": [
    "benchmark.description = \"Updated description with expanded scope\"\n",
    "benchmark.version = \"1.1.0\"\n",
    "\n",
    "print(f\"New version:     {benchmark.version}\")\n",
    "print(f\"New description: {benchmark.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95505c",
   "metadata": {},
   "source": [
    "## Saving Your Checkpoint\n",
    "\n",
    "Once you've created a benchmark (and added questions — see the next page), save it as a JSON-LD checkpoint file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf6e3fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-06T00:31:41.593841Z",
     "iopub.status.busy": "2026-02-06T00:31:41.593792Z",
     "iopub.status.idle": "2026-02-06T00:31:41.596110Z",
     "shell.execute_reply": "2026-02-06T00:31:41.595934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: my_benchmark.jsonld\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "# Save to a file\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    path = Path(tmpdir) / \"my_benchmark.jsonld\"\n",
    "    benchmark.save(path)\n",
    "    print(f\"Saved to: {path.name}\")\n",
    "    print(f\"File exists: {path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005a8ca",
   "metadata": {},
   "source": [
    "For details on all persistence options (JSON-LD and database), see [Saving Benchmarks](saving-benchmarks.md).\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [Adding Questions](adding-questions.md) — populate your benchmark with evaluation content\n",
    "- [Writing Templates](writing-templates.md) — define evaluation criteria for your questions\n",
    "- [Defining Rubrics](defining-rubrics.md) — add quality assessment traits\n",
    "- [Saving Benchmarks](saving-benchmarks.md) — persist to JSON-LD or database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
