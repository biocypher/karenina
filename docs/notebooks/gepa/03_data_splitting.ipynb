{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Splitting for GEPA Optimization\n",
    "\n",
    "This notebook covers strategies for splitting benchmarks into train/validation/test sets for GEPA optimization. Proper data splitting is crucial for:\n",
    "\n",
    "1. **Training**: Questions used to optimize prompts\n",
    "2. **Validation**: Questions used to evaluate candidates during optimization\n",
    "3. **Testing**: Held-out questions for final evaluation (prevents overfitting)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent.parent / \"src\"))\n",
    "\n",
    "from karenina import Benchmark\n",
    "from karenina.integrations.gepa import (\n",
    "    BenchmarkSplit,\n",
    "    questions_to_data_insts,\n",
    "    split_benchmark,\n",
    "    split_by_attribute,\n",
    ")\n",
    "\n",
    "# Load AIME benchmark\n",
    "benchmark_path = Path.home() / \"Projects/karenina-monorepo/local_data/data/checkpoints/aime_2025.jsonld\"\n",
    "benchmark = Benchmark.load(benchmark_path)\n",
    "\n",
    "print(f\"Loaded: {benchmark.name}\")\n",
    "print(f\"Total questions: {len(benchmark.get_question_ids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## split_benchmark(): Random Splitting\n",
    "\n",
    "The primary function for splitting benchmarks with configurable ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic 80/20 Split (Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default 80% train, 20% validation\n",
    "split = split_benchmark(benchmark)\n",
    "\n",
    "print(split.summary())\n",
    "print(f\"\\nTrain questions: {len(split.train)}\")\n",
    "print(f\"Val questions: {len(split.val)}\")\n",
    "print(f\"Test questions: {len(split.test) if split.test else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70/20/10 Split (With Test Set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train, 20% val, 10% test\n",
    "split_with_test = split_benchmark(\n",
    "    benchmark,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.1,\n",
    ")\n",
    "\n",
    "print(split_with_test.summary())\n",
    "print(f\"\\nTest set size: {len(split_with_test.test)} questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducible Splitting with Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use seed for reproducibility\n",
    "split_a = split_benchmark(benchmark, seed=42)\n",
    "split_b = split_benchmark(benchmark, seed=42)\n",
    "\n",
    "# Same seed = same split\n",
    "print(f\"Same seed produces same split: {split_a.train_ids == split_b.train_ids}\")\n",
    "\n",
    "# Different seed = different split\n",
    "split_c = split_benchmark(benchmark, seed=123)\n",
    "print(f\"Different seed produces different split: {split_a.train_ids != split_c.train_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## BenchmarkSplit: Working with Splits\n",
    "\n",
    "The `BenchmarkSplit` dataclass provides convenient access to split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = split_benchmark(\n",
    "    benchmark,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Access train/val/test lists\n",
    "print(f\"Training set: {len(split.train)} KareninaDataInst objects\")\n",
    "print(f\"Validation set: {len(split.val)} KareninaDataInst objects\")\n",
    "print(f\"Test set: {len(split.test)} KareninaDataInst objects\")\n",
    "\n",
    "# Get question IDs directly\n",
    "print(f\"\\nTrain IDs (first 3): {split.train_ids[:3]}\")\n",
    "print(f\"Val IDs (first 2): {split.val_ids[:2]}\")\n",
    "print(f\"Test IDs: {split.test_ids}\")\n",
    "\n",
    "# Check the seed\n",
    "print(f\"\\nRandom seed: {split.seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## KareninaDataInst: Question Data\n",
    "\n",
    "Each split contains `KareninaDataInst` objects with all question data needed for GEPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a data instance\n",
    "inst = split.train[0]\n",
    "\n",
    "print(\"KareninaDataInst fields:\")\n",
    "print(f\"  question_id: {inst.question_id[:60]}...\")\n",
    "print(f\"  question_text: {inst.question_text[:80]}...\")\n",
    "print(f\"  raw_answer: {inst.raw_answer}\")\n",
    "print(f\"  template_code: {len(inst.template_code)} chars\")\n",
    "print(f\"  rubric: {inst.rubric}\")\n",
    "print(f\"  few_shot_examples: {inst.few_shot_examples}\")\n",
    "print(f\"  metadata: {inst.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the template code\n",
    "print(\"Template code:\")\n",
    "print(inst.template_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dict (for GEPA)\n",
    "inst_dict = inst.to_dict()\n",
    "\n",
    "print(\"As dict (keys):\")\n",
    "for key in inst_dict:\n",
    "    print(f\"  {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Stratified Splitting\n",
    "\n",
    "Preserve the distribution of a metadata attribute across splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AIME questions have 'custom_part' metadata (AIME_I or AIME_II)\n",
    "# Check the metadata\n",
    "question = benchmark.get_question(benchmark.get_question_ids()[0])\n",
    "print(\"Sample question metadata:\")\n",
    "for key, value in question.items():\n",
    "    if key not in [\"question\", \"raw_answer\", \"template_code\"]:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratify by 'custom_part' (AIME_I vs AIME_II)\n",
    "# This ensures both AIME I and AIME II problems appear in each split\n",
    "stratified_split = split_benchmark(\n",
    "    benchmark,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.1,\n",
    "    seed=42,\n",
    "    stratify_by=\"custom_part\",  # Stratify by this metadata field\n",
    ")\n",
    "\n",
    "print(stratified_split.summary())\n",
    "\n",
    "\n",
    "# Check distribution in each split\n",
    "def count_by_part(insts):\n",
    "    counts = {}\n",
    "    for inst in insts:\n",
    "        part = inst.metadata.get(\"custom_part\", \"unknown\")\n",
    "        counts[part] = counts.get(part, 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "print(f\"\\nTrain distribution: {count_by_part(stratified_split.train)}\")\n",
    "print(f\"Val distribution: {count_by_part(stratified_split.val)}\")\n",
    "print(f\"Test distribution: {count_by_part(stratified_split.test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## split_by_attribute(): Attribute-Based Splitting\n",
    "\n",
    "Split based on specific attribute values (e.g., train on AIME I, test on AIME II)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by AIME part: train on AIME I, validate on some of AIME II\n",
    "# Note: This requires questions to have distinct attribute values\n",
    "\n",
    "try:\n",
    "    attribute_split = split_by_attribute(\n",
    "        benchmark,\n",
    "        attribute=\"custom_part\",\n",
    "        train_values=[\"AIME_I\"],\n",
    "        val_values=[\"AIME_II\"],\n",
    "    )\n",
    "\n",
    "    print(attribute_split.summary())\n",
    "    print(f\"\\nAll train questions are from: {set(inst.metadata.get('custom_part') for inst in attribute_split.train)}\")\n",
    "    print(f\"All val questions are from: {set(inst.metadata.get('custom_part') for inst in attribute_split.val)}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Note: {e}\")\n",
    "    print(\"(This is expected if the metadata field doesn't exist or has no matching values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## questions_to_data_insts(): Manual Conversion\n",
    "\n",
    "Convert specific question IDs to `KareninaDataInst` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all question IDs\n",
    "all_ids = benchmark.get_question_ids()\n",
    "\n",
    "# Convert first 5 to data instances\n",
    "sample_insts = questions_to_data_insts(benchmark, all_ids[:5])\n",
    "\n",
    "print(f\"Converted {len(sample_insts)} questions to KareninaDataInst\")\n",
    "for inst in sample_insts:\n",
    "    print(f\"  - {inst.question_id[:50]}... -> answer: {inst.raw_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual split using questions_to_data_insts\n",
    "train_ids = all_ids[:20]\n",
    "val_ids = all_ids[20:25]\n",
    "test_ids = all_ids[25:]\n",
    "\n",
    "train_insts = questions_to_data_insts(benchmark, train_ids)\n",
    "val_insts = questions_to_data_insts(benchmark, val_ids)\n",
    "test_insts = questions_to_data_insts(benchmark, test_ids)\n",
    "\n",
    "# Create BenchmarkSplit manually\n",
    "manual_split = BenchmarkSplit(\n",
    "    train=train_insts,\n",
    "    val=val_insts,\n",
    "    test=test_insts,\n",
    "    seed=None,  # No random seed since we used explicit IDs\n",
    ")\n",
    "\n",
    "print(manual_split.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### 1. Always Use Seeds for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good: Use a seed\n",
    "reproducible_split = split_benchmark(benchmark, seed=42)\n",
    "print(f\"Reproducible split seed: {reproducible_split.seed}\")\n",
    "\n",
    "# Save the seed with your optimization results for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use Test Sets for Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good: Reserve a test set\n",
    "proper_split = split_benchmark(\n",
    "    benchmark,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"Proper split with held-out test set:\")\n",
    "print(f\"  Train: {len(proper_split.train)} (for optimization)\")\n",
    "print(f\"  Val: {len(proper_split.val)} (for candidate selection)\")\n",
    "print(f\"  Test: {len(proper_split.test)} (for final evaluation only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stratify When Distribution Matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good: Stratify by important attributes\n",
    "stratified = split_benchmark(\n",
    "    benchmark,\n",
    "    train_ratio=0.7,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.1,\n",
    "    seed=42,\n",
    "    stratify_by=\"custom_part\",  # Ensure both AIME I and II in each split\n",
    ")\n",
    "\n",
    "print(\"Stratified split maintains distribution across splits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Validate Splits Before Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good: Validate the split\n",
    "split = split_benchmark(benchmark, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1, seed=42)\n",
    "\n",
    "# Check no overlap\n",
    "train_set = set(split.train_ids)\n",
    "val_set = set(split.val_ids)\n",
    "test_set = set(split.test_ids)\n",
    "\n",
    "assert len(train_set & val_set) == 0, \"Train and val overlap!\"\n",
    "assert len(train_set & test_set) == 0, \"Train and test overlap!\"\n",
    "assert len(val_set & test_set) == 0, \"Val and test overlap!\"\n",
    "\n",
    "# Check coverage\n",
    "all_ids = set(benchmark.get_question_ids())\n",
    "split_ids = train_set | val_set | test_set\n",
    "assert split_ids == all_ids, \"Some questions missing from split!\"\n",
    "\n",
    "print(\"Split validation passed!\")\n",
    "print(\"  No overlaps between sets\")\n",
    "print(f\"  All {len(all_ids)} questions accounted for\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Function | Use Case |\n",
    "|----------|----------|\n",
    "| `split_benchmark()` | Random/stratified splitting with ratios |\n",
    "| `split_by_attribute()` | Split by specific attribute values |\n",
    "| `questions_to_data_insts()` | Manual conversion for custom splits |\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `train_ratio` | Fraction for training (default: 0.8) |\n",
    "| `val_ratio` | Fraction for validation (default: 0.2) |\n",
    "| `test_ratio` | Fraction for testing (default: None) |\n",
    "| `seed` | Random seed for reproducibility |\n",
    "| `stratify_by` | Metadata field to stratify by |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [04_scoring_deep_dive.ipynb](04_scoring_deep_dive.ipynb) - Understanding score computation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
